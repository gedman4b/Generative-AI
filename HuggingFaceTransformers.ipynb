{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3559d190-6fa5-40e4-ba67-eeba4ae1bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore insignificant warnings (ex: deprecation warnings)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "938193cc-b174-4b04-a8c3-29b8c96ab24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b9461e9cf84918b7d5d77d8fd1e7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe735f6e7004dfda1d63a71969e17e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ffc4fb678af47e18e3f175af9e447eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f16a159b4fc4381bcdd898cbc6f08bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e803878-1251-4fc6-bb81-d384de899862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997795224189758}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"We are very happy to show you the ðŸ¤— Transformers library.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89116c5-c12b-4d24-9f17-fa8a51b3d2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: POSITIVE, with score: 0.9998\n",
      "label: NEGATIVE, with score: 0.5309\n"
     ]
    }
   ],
   "source": [
    "results = classifier([\"We are very happy to show you the ðŸ¤— Transformers library.\", \"We hope you don't hate it.\"])\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad6f2f1-3211-409f-907f-d4e8246bfe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "speech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4f492c6-651e-48f3-bb10-dfb251bf9257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea8f854c-1dfd-42ee-b615-98150adac7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9e7506c-c24f-4fdd-a472-b1e4c5e7c5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT', \"FODING HOW I'D SET UP A JOIN TO HET WITH MY WIFE AND WHERE THE AP MIGHT BE\", \"I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE AP SO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AND I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS\", 'HOW DO I THURN A JOIN A COUNT']\n"
     ]
    }
   ],
   "source": [
    "result = speech_recognizer(dataset[:4][\"audio\"])\n",
    "print([d[\"text\"] for d in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "514ffa26-1a2a-4ea5-b794-6b1fc0edef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41da6384-fd6d-4640-972c-7007bd83f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30128cc9-6051-4347-b732-7a47febe992e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.7272652387619019}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "classifier(\"Nous sommes trÃ¨s heureux de vous prÃ©senter la bibliothÃ¨que ðŸ¤— Transformers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198fe36a-522d-4048-b6ee-974136b6e6f5",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ccd6a59-3ca8-4132-8afb-3295ca5184c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\", local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8eca8898-a651-45f3-bb2b-ebd52f49da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"checkpoints/\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f1c0032-64eb-4ebf-8d5c-ba2693c3a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "487901cd-9e74-4dbb-9de4-3e64f3438cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")  # doctest: +IGNORE_RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b247e6b-d2c6-4e70-9377-5be7a6c1b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(dataset):\n",
    "    return tokenizer(dataset[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97020ad6-9020-4522-afff-6899b834573a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089813c152974baf9d64a47d9cceebfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf54e6c0e2984564b40d8d878458d07d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a188233f5d445698c8a0bb56564865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize_dataset, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a207956-a292-4c68-af57-3338c4a81f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2094e79-14d9-4f0e-b7f7-00a48ef57309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")  # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cba3091d-45e8-4350-8ae0-d304c419c649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2134' max='2134' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2134/2134 18:23, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.458300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.379900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.270500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.232100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2134, training_loss=0.3339979212867286, metrics={'train_runtime': 1103.6937, 'train_samples_per_second': 15.457, 'train_steps_per_second': 1.934, 'total_flos': 195402349287000.0, 'train_loss': 0.3339979212867286, 'epoch': 2.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6b1bdae-9c05-46f7-a581-22d320bdd125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/wav2vec2-base-960h and revision 55bb623 (https://huggingface.co/facebook/wav2vec2-base-960h).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "transcriber = pipeline(\"automatic-speech-recognition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09007d12-44c7-4ebd-a5de-3b167cb0633c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP LIVE UP THE TRUE MEANING OF ITS TREES'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriber(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d0b99-2c7d-4667-b31a-60f8820eca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriber = pipeline(model=\"openai/whisper-large-v2\")\n",
    "transcriber(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dee8ab-ff9c-480f-89e0-e163dc1d1998",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriber = pipeline(model=\"openai/whisper-large-v2\", device_map=\"auto\", batch_size=2)\n",
    "audio_filenames = [f\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/{i}.flac\" for i in range(1, 5)]\n",
    "texts = transcriber(audio_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c5ab7ff-6a18-4eb7-a521-edcb406a0047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': ' He hoped there would be stew for dinner, turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick, peppered, flour-fattened sauce.'},\n",
       " {'text': ' Stuff it into you, his belly counselled him.'},\n",
       " {'text': ' After early nightfall the yellow lamps would light up here and there the squalid quarter of the brothels.'},\n",
       " {'text': ' And in the medium submerged branches, some birds of the chimerical and legendary plumage flutter.'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dad3c81f-a937-4ed5-9dea-ee265478c560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at hf-internal-testing/tiny-random-wav2vec2 and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.feature_extractor.conv_layers.1.layer_norm.bias', 'wav2vec2.feature_extractor.conv_layers.1.layer_norm.weight', 'wav2vec2.feature_extractor.conv_layers.2.layer_norm.bias', 'wav2vec2.feature_extractor.conv_layers.2.layer_norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"EYB  ZB COE C BEZCYCZ HO MOWWB EM BWOB ZMEG  B COEB BE BEC B U OB BE BCB BEWUBB BXYWBESWYCB SBBB SSEZ C Z WH UB F IGVB SB Z<unk> XOES CZ BBXOXFBB  OBY W B VM OFOWUONFWB ZCX B M WZ Q S C Q BC CQBF FOMB BOT ZWYBZ WB  B CM B C B WZCWWW BHU EOYTO YWB BZ SHZBGEM Q OO T B BM XZ QW C OFBZMSEHB BE ZZBX M Q XB<unk> CEVWZ FOHSB W B O Z ZW S ZB O VM <s> D EUCKH XNC D Q BG B O BW U  U  MBE CBYE  WB HFQUBQBUWZ B MW BMPY F ZBU  EB B WBOF S XFOBB ZB X B MOT W B CEO WBM   BBXBBEOBECB B UM C BP FMBWB BZ WFCED Z B B FXB Z OZ OBBZ NVD UBZC W B WYCWY X CE CW B WB MWU BWN B DECF GEF'C WZS CS BYWB<s>FZ'Z<s>ZGBU ECFEY BF ZOZ O UWBSSZBBBBW   O O DBB BZWFUW ZWOZYCGOYCOT WC O CZ BD BBBBBBX X W T B BC BZC FWYBFO FBCE X Z PEZ CE B WEDBMBO BN B BY Y  W B BMCB XOXQ  BSZES Z M CF S FB BBXBB B C CSZ EF SEQF S BEC BNO BN  SU EH  WRFBS WB  W B OEZ WS X B F B X ZBBE BBEHB B BU BECBSXHB BSQWFW BSZXH BWSEG W VQETZMCZ UCXW Z DBE<s> O SXZX MB W RX YYOBSUBWOCFYEF O B O B C Z UBEZBE BTB C   CBFCB V W B BF W ZBBESBBECUT OH YCGZE W BYZBYGBEW BSBE B  B CBEBEBU BU OQB OSB CB Z Z Z HZGTXZ USZFB FC ZO C\"}\n",
      "{'text': \"BE BESBEBEZ WOE FO Z ZOZ NOS  SUCW W NW 'Z HB Z GCB'Y YNBTB T E Z  B BERB ZBWB SQBESB  S U CBWZ EBBZ Z ZBEDC BZM F F ZFZ H E C B C MBDWB BX  B B W ZWMOU B BZBBXYC ZB YB Z BUV B B MNTNZDZ GBNWF   OOOXF CEOF WBSS <unk>W NVC BCB B U UBEZ O OW B D BWZ <s> BY MEB FNT OZBR  WWFFCW  SC U GBSB Q B HWB Z C M B E BS CW BB B TZ CZ C HDSCE<s>XOWWBBQXFW BCSWQXF BBZXQWZ B BBZ XZWY FB WBSQXFE BBOWZERB WC CW W BFWWWBWWBW 'ZWEBOB SU BF Z CT B E BZT  Z DC W ZMCBF WBYZGCOYZBFSWC BCF<s>MCSZ B ZBUCZA WZ  OSW  DB EDBZWDBZ Q EOGCBSC CS ZC QE CBC OFH  BE X BZ ECEB ZB E QEOB B CZBEZS T C WZSGWFCQ<s>E  BBSB OXOXOW  BSS Z OUWCH E B MZ FZBFBBBWZBSQQW    EDU BSEGBZEUBBUOEDX<s>SU ZZWZ Z Z C CZSTWO B B C WZW WBVTBS ZU UQBESEBSEBSEQ FBSX BOX W BOF O   FX Z B C WZWZ TYBD Z XZB UEBTOCB B  OBBMOBS WFZWMB B HBSZO Z FZQZ GE O B UB ZZUEOBZ B YBUQBEQ ESBE B ZBZQB SBU B SBEBEQB B CB WBEWBX CB ZWEW\"}\n",
      "{'text': \"B OB ZBS Y MF BUZ BZZ UZCOEZ EZ FD E BDB CO QGD GS B TZC ECND ODGZE  BZB UZO T ZHB Z H B B R B  B S O ZZC MQZOEO CBF  ZWDWQSZED TB CXZ BVFW SOC ZEF T FONZBF UBE TWBC COZY CZWB ZTHVNWB  CNHWZH TWX U DTZM F BNZMWB BY EB CBFH EZEWDZSVSZB S <s> CZT EDUWCB EZOU UBFBWOTBW G X B E E BNOCZYR  BY G ZXE B CBEOG ODZB SBMYEMB BDNFQCWM BBBOXOWB BBB B CBE ZSFNDF ESBOCB  B MOZEBSB Z OWTBQMBZ SZSE B FW WBG FWEQNBFE HBHG BC BZRZBXBZ TWBWFOZWB WY UY SFBWZ F BC</s>BTBQ BEZ WZWZ CBSSS WO BBEOZ BYWZY BYEZ WSO BWCBCE G XCXS T W W MWO EB CB XQ B BZV XM UB B CU C Z BOQXFEWSQX SQF SZWEWSZX SOU ZFCS OX<s>BSB WB CE BMCS ZES WSZXE SZBESZXSZ XBTEB WC BCBEQ WFB B SE B F Q B ZXZYBOEYXB W BD C OQWBXF WBZBZCBZESB C B BZSG OC E B CM QBFC ZBS O CS GOC N ZB CUBWZF ZM BO TOOZ OB C GQ ZCZ C OB  BCBBE OB WG H ZCEDT WW B Z OWCEEB W G ZOU B B <s> B X BEBE B H OG   BZ E SCB B B OMCY WBZY M EWE Y ZSBPGOWZU  DUE UED EDFO VQ TBZW B CQQBZB O   SXB Z FBTB BB ECCE CB ECOB SZ B ZBE ZB W W BFB MWOBSZW  WM W BDB  BE BO B W BGW B BUETFHNBU FH FZ FGSC 'BBU  E BXHB ZBS Q CT OQT BF XQRGY GYWD DX CZ BZEFVWZ OB B GB BC B H FO N WB    MXGXGXQWQWQWW OBMWBS OQWBZO OBWZ ZBZEDBZFZ OBWZ QUBB  HSW OBS X EO OEO CUS BOBMB B BFEFBSEBQZ S ZUB XB OSZB W WQ CBM  CESGBY Z  BCZ X ECGWY  ECB B  C C B B B B B BZWWZCMB B CZB BZT E WZYZM Y W OBQ B WB WBE FEBECMZBFSBO BEZBUZB BFWBEZU SB BEHMECUEB GSZ B BCY TQOU CSHZW W C B OC ZBZUBCZ BZ ECB YCOB B TZBB B SZBZW BZWN BQ MF ZUOEFGV WF C C YBQO WZ B<s>HSWV F QB WB E WBOWZSZWBUEOWGF MBZ B B O G W BCW B H WFWBZ CZCSZ Y YSYSSZZSSEBC B SY DUWZBHS  GBF CWCCFCZSBZB B SZMWT BZ WQXF BBQXF BSXSZMZ DZBWZE B B B CN W  C CZ WCZ Z ZBWB Z HYTWEHFEQB Z C FOX Z O BB B W   OW BEDTZEDZ O WZ WCSWOXEDE EW XFOZBB B ECW O YBF  SSFW S QODZ YC C WBU BE ZYQWZYY OCQWUK 'O B BBZT SZX S EB Z H W Z MVMHWFWBX ZWC  BS X    WZ  M FXWZ FZB BZTBZ ZTOC CYEO B VB BVW WB B Y FT YO O BFOFXBECEDB B BQWBEB  T T EZM B EXY WQBF WSCOWC W WB CW BCD  XSNC  SZ EB XB X SQX BZSB Z ZDBF Q WQS BZUDSOZ OB BECY BW B YZBD W CB P WFBSYWW EQXWES ZMOYBDBDWEBO<s>OU XB WCBMCW BE C ZB B ZEBMWB TSZSZ W EHUBBSB OM Z WQWM QW   W  BBBZB XO BOTXBT OOXOWF X WFE WBHB XZWFB WF XBBW CXZ WBFBONZOCBNBZBEB E OW BE DW  SEBSBUBE BU CNOVCBZR ONGD YB  OW CBX WXB YB  BEBEZBEO B WEFBUEBUEBE SBB B BBUEBESUE SM BTZBSBEZ B TBE\"}\n",
      "{'text': \"WZBZ Z ZCBWZ Z W O C ZC Q WC ZW G VM SOCEWB C S <s> WU E OE NHO ESOBT GTG XC BCBB  BE B BU OBZ S Z ZSQBFS<s>BZXFBE O MF B E YBZTOZ ZDSED D S T  C W XWZWZT B EYO S BSBQZ BE SBE EZYMHB Q Q Q WZ B CW BM V B WXZ W <s>WBOZ WS BEB WSEOBSBU B BBTB FD EFBC  F C  BW BY  BM WC BM T T BF BQWZXHE C M ONC O BCBWB NT ZOBDBWMTX RS<s>B ZBB BBBCUW B C  WQ SB U ZB Z OBBQMB  W WB SBGWZWCBTWZT BECZQ SECBMZCZ H C O FW WKZBQZBEZFO ZQH EQEOT Y B B CBS BSE ZB COXC<s>VZGMWUWZZSZZCDWZ ZW O CEF SX WZB BECB Z ZFB B MZ BZXO BES ZBZ D Z BBEBUB Z Q E  BM SB C UB CT  OM O O Q BZQSZBBQWO BBEF SQWBBF BSFWZSFBEU SVYZBFBSE<s> BOB B HBBSW BSH BS B EWBM C WFB CW TBBWQW WB ZB CW EYW WBM XB OB QMBZW BM B EB EBBEBBZ ETBZ ZB CESC FB BSSOWOXQ   OBZCZCZ OW XBY  XOSM QWB  XOQ Z O BY BY B WM Y TZEOB BOBEBX BECBE SBB XUBXBUBEG UD</s>FYZO WBBBY E XBX B MBMBMBMBMBMWOWMWO QWOBOX W  ZS T EU Y <s>YB B SZ EQZN YT MWBEBHWY F EUC W WZ YZMBWSMFBNMEOZ FZ BWZWBZ BZE Z<s>B B BUCB CDWSF EFWBQ B BY BZ W ZN ZWZ XM F F EC W  Z E MBZ WSXFBYB B HZ BZB B D OE SBQX F SB O SBBZBZ  EGZB ZW Z OBZ ZSZCZ BO Z Y FHOEC SCOCZ CZ Q E ZFOCE B FB X C SE CQW OET WTZOE Z CZY<s> Z GZM BFM<s>BD BECBB B ZYZY Z NWOD WZ ZCSZED  X B OM OZWMW F ZBFOU UBBS CZ GWS EDWZBZ DWZWS EHBBZ ZWZ XB CQT OQ BE BNQ BYCMBZ BEB TF XZBBZC B BCBCBOBOZQ HZFXCW WCZ WBDC WBZ  REQEGDM V B C BZ Q QB  DB  F OCWZC WCBZ CBDFBG NT E B XBSXBS BZBE BE B  Z  B UMZ  COWYB BGWBOX S C BW BYM Z BM YS BEXBM W OT B OZ B  CWBZQC HFXXBEZBGXF SXM WM WBE O  VZN CBZ EYW OBY BYB B BMB  B C QSHXU EB Z SFW C   BZBFB BSW B<s>BB B F ZOWEZ QO SBBS E SEB B Q B BZX ONBESFCBWHWQ CBEB  HWN OB E O CEBBXEEBOWB B T H BZV B CB WBM BYBZBDHOGBXYQ B   OC B B OM R WZU CSWB ZOFMEYBZ CBYU BSWBUES S E  ZBEYFGE DBZ ZC W CEBF B Z OLWH V ZB BE ZB' MFOB BWBECBSBY EUWO'<s>F EBEZ BMCBY XO B OGU S R OBZ B Q EBU  BEOOBCB B DQBXB BTB BEFBU BE B T BY C\"}\n",
      "{'text': \"BSXO WB B F G BP SZ  B W T EC BZNBSZ BH U FOMCOMC Z ECOMTSBZ CBY BF   U BEBETB SB Q M BE UY SBESBZ EO BBSZ Z ZZT T T OUTUTU UOXOEO OXDZBCBCEWZM VYWFXZW TZ YFZO YZO  D  ZBO Z BF BC Z BF BMSEQEDUYNC O VNTCYBZYF OEYZEWZB B Z B U ZZB  Z  BSF BQE BU GCE T Z GZ CB  C B OFB Q BEDWV Q W   C B ZWV ZE CGB UOHZ CMUYE Y EZE EWF B HKFO EBERB XCZWC GCEXESECZM CFTXCFYTCE O BEM TB FB MBY  E UBSFQ W  W TE M B CZU MNC  XB ZX  D B TZ DB BOM CDWDCBB C D CZDZDBD D WWBXBECBZY W BCFBU EBZBZSB ZO W OGC SZB UD  UZ WB  BFBXCB  EYZB G EQBO EBGBEGFB ZB S  B  UVBE B B  UEG Z  MEC BX BU Y ECBSBY MZB OUOBUBZCBECB Z OE ZBEB B Z M   BZ FCQEY  Q    BSB ZU OXOSOZUBZEQFEDC F COSCB W WSGWZEZ EOT  TB W C BE RYBO B WW ONOO B T B ZF Z S OX   SF SQWBEOBSB BZBU YZ WXY BQYWB EBEBZ MB CBNZB EUWB<s>B O BT B M G E BBCS B W W BSEB XB B BEC CEOU WN UBG WCB W X BXY N X CB ZFBSEBXTWBESC YZB TF S BB CT E SVN B FSBUHWB OC CDB Z Z QZOB FCDN B Z WZCOG V BO OCBZC FC B B CD OCB C OBQX EZBUSB B  BUE H CEOWVCCZ  WO O  BBS XOE BBX<s>EC BSBZ   W W  W ZWZBOS T ET CZ O ZNUEGBV NOOXF C BBQXFW BSS Z P'ZCU OZCSEUCBW FMO O B YZC OZEGQB BU  VZSUEHBEUZ  MIBFSVZ S Z Z HEPF E OFKSZM Z SRZM<s>B B EOEBZ WD OBY FZBXOQW X C W Z BZ UB EBZYS Z B SBFB BDU   WZMTWCSZOBXE C B B ZC  CB WW C X BZM SUC WT CZQEO B  B WWWS Z WBBTQBZOWOBDQZZSZW BT ZCXSB WMT Z YWZWZM C<s>  CZVG EGY<s>YXO CB O H ZOZ EUBYX C SC</s>Z BSF MFE YB CFZ TWSUO X YBEYC M E ZXM X SC BBMBS BEC W CBY Z B QYX Z BY  NZV ECW GBX SG EEWO B ECNB BWBB B B BF S SBNCYTW XYN T M OE FO C ZFZFE FBC BOCDZU ECZY VZBW UZV F X BZ MOZBOCO S CZ WZBCOC BD C Q  C VYO C WZ BOBO F FBT  Q X SCF SE EHHUFESU Z WOEOB B WBE BOB B OVOM E B F DZCZEDWZ DWZSZ DUEDWGSZ OSW     SZCRCM B BU Z BZ WBE S YX B SW B QWST BECX BMSXBOB ZBE SYDBXTMBOXC ESX<s> CBYBNSZMBESB B X B B B B WZB SBYBXB SOBBCE E G U B BZ BBBEB CECB CU YSBFE C SZ Z ESYC B HEZ OMDZ NMC BOYFU B CB ZBTOBY SB BEBFETBS U B C BWB BEBBTOBE B OB <s>BXB BE E B B CBBX  BE BEBEOU B ZB B' B  Z MCBOIE OMON BO ME ZCZFWZ X<s> OZCUCB W WZ BOEO HSZ YZ UZCEB E CZQ Z YONQB WZ Z Y WSWSWZNCB MCB GCB O Z ZF GXZ FQMHZEZH Q BEZTBXOB BMBUEBE B OB OWZQ BBU XBESBUFBEGOB  B SQ OUFBBSZ OCD N CN <unk> R YC FCT EB  MCZSY XBXOXOEOWBBBOEOEOXYB BFCBE BDMWCWQ D H B C SOM MCO FOMO O B B QU WFHY MBZMBWZ FGDYN D TZCB YCW E Z OSZBF COBZ C WBZBWCWUOCZU Z WBY WBU CQ ZO W BZ W BW B Q CW BM  CB H WBUW WYA CB T OB S QT B B QX BWC O BNB CZBBBZ WW  WZW DZ WFWZ DS W M A WZBZ YBY GTZS OUO B BZCZBCWBVOBQCZT B CSBX U FWZBOZS  Z OBVFU BMY CWOBEM MEHZ  BU BECBHBESZBV EZE Z ZFOSSYEB OZS CBVBSZBZ BS Q  CBEFEBBBQX S F BO EF MZSZO Z B D ZBO S BZ BZ WFF WF P  DBBDBEOB  BQT BEZBYMBZBZBC CSBD BYBZBY BCBSZ E SB ZXZBET BOT Z F CXSMB XBZ FWWBSFE BZOS XFXO F        OECBSZ ZCMWC C O  FOZ Z FOXEFYBNHO F DBOZNFOZOV WNZY X B X QOY   XFW WBB QWFEWSSE BSEDZ YOBEG VC<s>BZ CC ZC D Q OC ZWCH   F  WWWQBOO FWE BSB  XOEO WC V X WBWZZ BBO X E FO BF ZBEQB OZ  ZWS TS Z NB ZV W B T B T TB  SBEQWFBBSEOX BSOOSOFCSOG WN SBYEMBNBRSZ Z P VEZMWSBUHWHB T CBGCZ B SZME BG ZC SZBZT  ZC ZXCBDBB WFB T T OX OC EBU COY  DEBZXOBQT BW BMW BBWB BECWW BF  BCSEHU E OBGHB  FGHBZOS <s>Q<s> ZTS BG ZFOV B GN EFB BE HZ OBEHBEOE BSHMFEW EXHZ FZ FCSZ T T W Z OZH Z Z HBEZFZ B W ECFO  BZCWB BZVEFOF  Q ZU TBWUVCB W GUS B CEZ WS WB WEZ WOZ BBZBW  BSX Z XZW WHGUV N BZTE S X BEHY BZBW Z B CXFQVZ HE<s>XQ BTBCBUH BCHBYUHYZ UQZ <s>IZ B  QONC VYHVWZWZWUECSZW XE B CZBGB BBXET WZBRCB YHC ME Q IQ WCWBG W ZO B WDBZHH IT CBEMVWB  BESZB OBETBWB Z BE B B B BE BE B B  WB BEZFBEB EQZXZBU BEBF BESB B SB BZX ZBX BESBE EB BEZ E BCBUBW WBEZ OWBS ZR CMZ WFB WF O BECTSMQZ O N GZ <s>GB S Z O B Z E OBEB  BEW B  B B BEBZ G BCWZCE OWZQ F OBSB  F  OXOXO  ZCE</s>OXZSBXFZ ZC RGUECB FOZOZ RF GTSZCZCZCZS XO OW BBZSBZ S G IOENECOWWDZ  TZQ X BMZQEWBSFE WCOXOB UD B B B EBCY M B F C C ZBZES W R XCZ WB O BE BZOQ BZMB B O BZ QWWO XFBSZOTB OWBSS<s>XDWBBB BW Z COC Z UBMOEBBZOR QZ NBGO C Z E GMTNZ Z B W BM BEQBW CHBU FOH FZ BGB TB  BMTZ WZWZ QBCHZFH UF H FZEDM BBW BHM MZWB W WBOXZSWSG X C ZK VXBC NBUOEWX E YC W EB ZOWOBQ Z YCY XO E Y F WMB BMC B ZYW C WBSB CB BZ BEB B  EZBBE S WT WZ SE B CXBBWBE BOBCB BZBD CB B X B ZM YZYZA TEFBF<s>Z FB DWQWVY GMQ X BXSM COZM FOZ W OZWFDZWZX BZ EC ZF CBEBNB WBZBE  BYT B YZBG Q BD Y GTDWZSZ Z ZONY ZTQ I WY WOBMQZM  <s>BF ZCZ BCQWBOEWDBZ X ZC O W WBW M  WB B B EC UE BSB MWBU N B B  ESSB   OXF  WWBSZBB SWZWC   BBSBB EBED C ZW B C FO ZB Z F W Z YSO Z EYBE Z EZ E </s>YBQB BYWZ EYB ZBE ZEZYDGEG YU  U OUBTZM EUONC O EUZF OXZO  ZZNWZC WBWB   BB BEB BZ B B X SYB WBBBU O S C T OEO C ZB B S  BEB TO ZUZXOESB BES BSE BSM X WF B Z BESBZBZBE BSXF B HN CZRCOWB  DWCBZBED BEQBZW W T YB CBGW EYWXBWQ TZSY XSOEX WY E B OBH Z CY U COB BCZBB D   BF S WZTF SBWBN BS B SOMWW RBZ BWZ SBB  XBUBFBBBZB GQ ZB Z BCEZ SZCN X T B BO WCWKBG  FWZTZOEBNWB WB XWBOO O BBSEH FBWBE ZB ES BZ WBBO T ZB BZ FEFBBCZCEZS S Z   C C C Z Z Z   CO  W B WWB W B CW OEZOEBQXBG   Z BZ CDOZCBWBWX XCBE B B BDG ZB  WC CZCOWBTB C TZBEB BB ZU WBB CQBX SQWZF B B O SB B SWB BWSBE  B B W ZYFB Z F EZYR COZECBZ M OS  OBBGBZ  SF W NOB <s>O ZM B X DCZ ZOQFCX B G ZCOBZ S</s> BYBO ZMY N WZ BO CBXS ZEBF FZ GB YC OY OMC GT B O CBW  EB BX B  XF        OBCF FWBZWB O MB  OOBZ W Z YBO S B CMZ WBEBBZ OBWFXZ CB OFGW FG S O W CZ W BZ Q CZ  CZWWBUE OWFW  ZBZESE BB EZH OZ C FQ BXC DC Y C Z SWB YZ XZ WZBW B MBW BZEWBU B Z BB BE B BX CB B ZB  BESE\"}\n",
      "{'text': \"O HW ZRBMCUBC WOG O YXZNYQOHWZV GF WZ GEKWBF  UOQ QS ZCBT B E C YOUECBEB FB CBBCBB EO ECBE BUZTHBB CFCBEO CZ Z Q W FSS  C F O B BWWCBEHWB BWCWXMCBMNB WCBVMOZU ZO   ZCWEZC FZ WOET BZ YWSSSSSBW    Z X M B B FBC  XSE FE<s> OF WCR WM BT ZYEZWSOU Z BCGTW X BXCW Z B BZM WCTBOCZBZT C G Z HN CTZWBF     WBZSE BSQX BBQXFE O  O DB Z N O W FYQ ZEZ EWCFWFYZ WO  C CYSFV FU EFCFFBCW Z SBDB B SY BZWSC BEZB WSQZ WSFUEZEHBFEO BMWBYOX BUSOWBS F B NC OYBEYOBBYB EC C BCM WDBNC XEBFBYB FBB BOG Z BMYN Z G  M BI ZWB MCNWBZX ED C<s>XQ BBEGSE BE BESB  B BE CB BUW C C BZWZBOWZW ZBOZ W UOOOOEB B  Z EBSFHT FT B CN YSB E X WBE CB SOVZ CO Z OT E B B O EB SECWU W B CZY BZT SY W BY BS Z W BBEQ BSEO BSEO BB XQ BBBB BZT B OMWY B Q  HDEDWQBZ QBSS  ZBOBOW BSQBFW B W  <s>OZ WUZB VB ZWZC CZ OBM B B BU Z Z C B FEBZOOD WE SYB MW V B ZB B B BXQ HBWEGCEZ H Z Q H V FY XV Z M FD BZ B ZV BWB R CB O N O T W BWSZCW EXBB WBZW SEYZ B GYZF O DBY N CWBZE WBWB SBDFBUSXC  B WE SCUZFGBFBEH STWBEQEBOX  F  B XBOEBQ TNCBV B HV ZB B BSBUWB WO I O OCEZBCZ BC W BFGM BZB Q E SBYBN QX  SBY XDY WZW F B  BZ ZTZ M ECBEG QB WY Z OWZDO  B<s> CZ ZGBZCZ BOQSC W WB ZB Z VHSCZSB NOCQWBM Z  CTBEC B M W YEHG FEF CSXB ZB B WFBO BDC ZFC CWB BDS EDBZ  FESBBCESB ESEZB'BX B O HB  QB GSB B D BN <s> COZ CB BYBXBX ZUZB C BYB W EYB O ZWM TF M M BZB SZDBSWZNQZ FBZ B CDSBEDWD OW XU YBZB CCC BOOXB X F X FOZEOBNMYZEXB Q YTZ O EMZ ECW BSBSS  WWOEXDI YZ EOZ WO YBBYQ O ZB B BZ MZ WFBOSZ UBUWBU Z FOB Q  DNZW SBZBYSX GBFBESNYC V B BZ S F EBCFB ZF'ST B ZBE ZB G X CBUW  W XDS BBW EBFB XBEGB BEB B E SUZU BEOB BC UE B EBOEBEPBCB BE BE F EBBEGSECBEOBUM B  B OF BE Z'CB Z\"}\n",
      "{'text': \"B ZVEGCBE BXB BBEMYBE TB  BX EG UZ UZGM <s>ZBG E B BCB EH  Y BE B OFBE UENOB B BCBESEZ EBEOBBEC WFXBF OUEMWB    BSBOWHBBB WF BB EGBBXBE BSOUOEOE FOH WB ZWDW QWZC DW EWEOZBDZZZOBSBQXB VNB S BZ BD B B EB BBUEBV O ESBT B ME EG F F ZCF  XXWDZY CZW CQYBKBT CB H Z ODCWZX BCEUZ OGBEB  Z W FBZBE  WWZWBU WSZ OZOBS ZFHBMOXQ CEHX O BS HXS'BU WSEB CBMB BVB SBESZ B B WWW CE YZOBHBZ BUBZ DB FBECBESBD EOBEB SUOE XOXDW WQ BBBSS OO Z OQ C WCFEHBZMHE FBW WD VCFZBN FC BZ<s>EBBEB Q B ND MOH BSYE O<s>MB XD CFCTBMBYBXB Z BFB TB CXWF HP O B MCSEDZZS WWYU B BOBO F F CXOXWWW SS WBBSEBBB ZUZ SXO W QW CSBWQ B ZWEBYM  CB BCDBZ W WB WBZBYSV XSZMYX  BDEBT BDMDM BOGZB EBUMB W SUBZ QB S H UC CEQ QSBFZB  B U BB B B CC SFD  <s>YBEGY M EZB TZBZB BEBXBW ON XBEB OZX BEZB BH SB B HWSEMB W CEBY B H BEFB XCXZ CX BX B BEGB B MBFBZDXY COBGB SMYB BTBZBTEZ CSYZ ZYEBYWSX WBZES BWB BUBE ZBCX B BX EZB BSEBEHEUOYA FYQG O OBGZBED BY EX ZSBW BZ CECBWSGZBZEWTB B EQBFW B SEBU<unk>NCB CE CUSCZSBEKM FBQ OEB B SB B BEH  <unk>FCX <s>N C BZ EBGBNVO W Z OD MNT Z VZO ZE BM ZO BC ZCFY\"}\n",
      "{'text': \"CZ  BEC GM FCBU BQZ BOB SBZCO Z YUE BUZ WU B ZEMOB CYWU OB ZBEI BXZR   U  BEWBBEZBEDB   BBE FBO B BSBBSCBWWFW ZB WZWZ DZW ZWCZB WZW OD B ZEC VC TBMWB BZ WSOFWB F ZTWBOBSBBBUS N V  BHCO B CBUBS E BQ BE BW Z  Z BG CXCX Z Z  SBMT TU    Z  E WZ BMWOCZ OUS WF XCM B XWZWC D C CWSES O C NC BWCBNU BC UWZG OT FXGB COB WB ZWWZ BWQ E BEC B WB WZ ZEHWZ SEDT OB CYCF UNE QBMYUBWZT NVGTBZH Z OBOU GB SG B O BZC EWZB BBCB CB B B B B BE BXZ E BEHBUCBEBZBVB X BYCB ZB TWOZ  EB BZWBZWWW B BZ BS<s>WB X S<s> BSZOCO W BDM X DO DZ  'E XW B <s>OWW  ZMY ZXW CUOXWB WSCB X OTZWFZM XBZOWNCBZWQF BBFD U YCU EB W MVF B S QBZBZ GT B B BBUCEZ WB OS W ZEZ TWZ WB GX B WBEBEWS WVZBZ <s>O ZE B BHEB XZWZ DY WOZ B MWBEZX S BMEUOZ OQBYF VFPOB  FB X SX B ZW XGSB WG BBBZ ZCZBB Z BY BZ SCWCBC S WQOX ZBTB EOBFVGQM F OBZ BSZHQ  CWB X EYTW ZT B BO MEB  DNZCYWBEHBEHO SBUEB SWEBE CB Z XOB ZCFZ O OZXMZ C<s>GQG GOEC WZOQB <unk>CZO B O OWS EFB OEZ BEOB B W HBEBU  BZZ BEWFOOB<s>EH OOQOXOXOXOXOOOX EDU BZBECB GOM WNUE F  BZ Q BDCG ZWBZ D ED B O ZWMW OFZ ZWZBZYHOB SBZ M O COUB BZW B W BWH EOCOEZW QFGBE  W ZWZBZOZBSBWWBSBB  XFE WWZUEVEGW  ZZFQ UZO C S ZYFB DBMXCOYB CZ W Q  ZBM  ZB X BUW BZBE B Z B FTZBT B WBEZ NB FM T OGTOGBFB BMWSZ WSU CBZBECB B C BXZEQ BMO M X BOZU CWY MO E CAFCBE B  Z C FCESB B BE E B  F BEB  B SB BZBXSBEZBE BX B BO BFX BEC EOEYHN BF  OZW OBZBWOSBEZWZ ZO Q SSWZ DOB C B OB C C CGO YB ECWGBZWBOQWZWFWGS GBWZ XZSCZS X E WCSZWS    ZBWXWZ ZD MZ  DBXBZ  ZDC BE C ZBCBW B QUBECZBZ F BQ OH X WEOB S FMCZ ECB<s>FZOBZ BB C B ZO X DQGQ Q Z CQOSMW ZEG WWBU Z NOZEWBMQOC' C MWZ O B  B ZOBUOZB  BG EU  YBO BS FBZZFBMQ BBEBU B  BE BU E B BE BBEGBETZBSB\"}\n",
      "{'text': 'E E YC GRWB VHNM YB  Z ONOZC T BO B BF   T OZBO WZYB YMWZ Z E XDGNOYO BZCW Z B BT BU MB BCBOB OZZB E BZ FCD T ESCYB CFSCWU B  B H Z ZOW YZ B Z BZWZWFBE FS  CUBYMF BECBSBY O BY BX BEZ YBZ O S  WBE WS Z ZBU BETB OYN CO W PZ TW T Z Z Z OZZWOWEDZXZEDZXF WCZ CZ XZ BZCU EQC  YTMOA<unk> U U ZBTWSBU B EB BEBECBUOB ZBB CWCM BWS HY EZ BECBD CBWB QEDWC W B SN  S CES BCSFBOWBS BZ T UB EBU CBXW BCTFZBDSZ D XWCZ CZU DZ DZY CDZ CZ CZW ZX CBZWFOZB CQB ZSZBS W EBBCBSECQZ BB B WZ WOEWCZ CB B ZXSBZW B CBW EBT  BYBZ BUZ BV ZBT B M Y CW TWCBZ BXBUMZ OWXBEB  B B B B E BEBESB WB B  E B B EYBB SEY B B EEMW WW BOOBDZDZD CWSSUSO ZTS W B CM ED BUXECZB OHZ HSB OUCFB B MF F V CH G UBOW BO WB B OZBE BE B BBE B B  B CB ECBEB B B B B BFZWWW   F OOOSSOBE X OZW ZY GSBSYBOME OW VFYB Z <s> Z MZF  WBZOZWSEB B ZBYBFSFBBBBBE BOB BBB  WF XZ UF CBEB SB BBEFBEF BE BB BE BE B COE S EBE WWBE BEB BE B BESBE B O E BU'}\n",
      "{'text': \"BED B  DECZ ZGR EO FOC ZOBP ZCG<s> FTHOWME WZ  ZDOQNCFGLSCZ T B FHNOBV TO U O CBE BT BOBE G  EBCBH H ZSCBH ZS OBVZCE BEWBYCB C O TBFE EHT S B B B XOXZW B CHT BF WB QT O O Z B FB EZX SS B QXFEBWZT BSUZ BBBQ QF WZOHS WCF BCF BWYB TE C B U DEC XWBSBWWWBSSSSBBB  FBCBZ  QZSXMBF WZ VZ C B E OKWCBZEZWYMH W Z S EOBSEBSEBEHB BQBUGZUYB  BT OOY M W B O WWOEZ TB B X MODE BM B H YBOZBZWEC X CB BECNS FZ CZ QB BWZ EBBWZ WB HWBSET SOYCE ZY OB B W B EOEO CXOXGXG G BT QTZBC B WYFXWOZB F OZBW Z D ZWY Y  BMYBZ ZFBSF QBMBBZCSS E SWNBF QEFNQMSG<s>Z </s> WBSZFG W ZZW B SMTWZ WMBSE CRYOTWOX CV WZ BXOUZ BBZWZWWS CX<s> BUSEE ZE OBX<s>WB WBB<s>EGB BEH S ZW BB BB  E WBSOQXFE BSSEC BSFW ZQ'W BB BBB ZWBZOEFO E B HEMB BQWSH SEOBSEBCBX H OSOX<s>WBSEOWU BZB B O F COHC WEBYMZBBSSWWBBSWF BO WBB WB X BXFB BUFBSSEUSEOEO ED WMBNB CNZWP B W F E  YEQHTE HFEZ   B Q B Z WB WBUCB B OBN FOSCWSWGBHWZF BT WNG CB FBUE BHBECBBMEOEZ CB B ZM WB Z  CZBM RB BFZBZSSZ SEQWO B N B C BGO  BEHB E E B B  YS H F ZX W W BYBOBBZBZ  S Y WESBQ WB ESNCF B SQEC B BTWBEC B B MMFYCB BEZEHOF OMH CZO O EY Q 'ZGSFN E Z <s>ZOZ DCM NCBCO OD EYNBC S O GQMCBNFC GD E FN SMMEU F BEZCMNDBU UMBOBEHZX HB HBXOEBBEGCBZU BEPQ S TB  BOE BY  WF SY  SYSZ OCESBSXO BSW SCX XFBSEO BSE BBXOWBSEQ BBEO F BBBBZBWBE O WQBZ DZWO XSZ BBZWRUH MBOCFU B WBZ STW BZWSEQB C BZQ XSU BB GT E N Q ZQ BBCZUZW BYX MFEGFUOBM  B C XEOF BFZFO X OF BTBSEBET HBE BEQ'G B S WBZY BZB B ZU QWC UEGHDOEFB QBFGQZ OBZ CS HMR HMZWS TWS TB WXZ S CY B WTWQ BZ TWYOWZSBZ XY CSE ZU   CVZ Z BNW W BC W OHD RXMB C OB OX  E ZECBXOB B  BE B CWZGCOQWZ ZSZWB ZZUN WZ YMOGB O B MBZ<s>OZOW WYS GNGXCBX Z OTZCB  EB BCT C CSEQ BE BEHMECBEH U B TZECE SZ WFETWBOT B HWXDSWCZECKOY E P ZB W COYWB BMC XEDWBCSMBZB BWF ECOEHQWB O CF U CMB BZQ WSZX YZBWBQS Y T CE BNSUBVWFY  ZSDZWOZ Z ZWBBDW Q EC WCBY QSB BE  QB B  WYWYZGW   WM M B CO VBWO B BZWO BMBO T BT  O WCQB B C  </s>FF SH BO  ZBBNH VEZ F BE B OXZOF EOWM QF  ZMCQ WB OB BE BEO O  T B EDXZOZGEFYB ZO GWBMW WZ BEDBBEZE T O CB YB SOFB W BF C U S M BZX  SW W BN O Y  EN W O QBZB V VEUOZBS SDSFBF'FE<s>EZBZ CFOY FCFBCX BOWFTMB SBYBYZT FOS B<s>EBBBTUZGF FGBBEBSYOOXFW CECECEF  Z DWEFSB SZTBHT C EBZ BCE B OZH WF BSSXOWFB BEHB S BSE EWZ  ZBZWDWD B B BSBSBB  EDS  BNBZEC WOW WC Y  CZ CZX FOZ FBZ WFCZ DH UEDWECSTV X T B CBD C QB WBD  OC SBEB  BEDW EBDW BZGUF CZ SNEZ OBFGG U<s>CVCYZBEBXUE</s>QBU V BM ZO Q ZC ZEOX C SZWYC B BZMS ZTQ<s> BEB M OE BOE  U OX      WB OOXWPX WFBY ZBYOXBXOXHEQW BOZB ZWFWZOBCY W SOBZ SZWOZ H X EMV Q OBEBZBSBWP BWZBO BESUESZ'EOB GHZCN  UM  BE WB CM B XMGWOWWV   X X  CV G C M MWMWY ZYOS Y WUG T OT B B ZEHXBBO E TZTOSOB XHBTG O E  X W WB</s>XMCEZB <s>EZB CE BO <unk> BEM O Z BGBODH W EESSEIZB TETYMO ZWEXE N HNM T OBE BOXOE BBSQZZZBWEGBYB B EEBHM GB O O EBY ZSW C BV WQU O HXF YB WW UB FG BOZOWZ DBZ EOEZBZ G E<s>BG CBS BMEWZN B B CZ B QWZBX WYBM ODB BFZFOBS OX  YBBZWCF F O O OXOWF  ZBBE U BFBEZB BZSOSBBFB B  W B BFWBSFZW EB BSE MW S F COWZ F WC WBZT S BXST B BBMWQM SZ S OE B QB VX C B BS BHWEB OSBEG BOB BE B O OW S MNCWECSWY W W CMWY </s>C B C YZ OZF OZBM   DY T EDUEDWZ O ZSBBNBFZUF BEZ F O EWL QCB CBZEBZWZC  FO CF STWZTWS SFBSS SF C BYB ZCYABZY U TYE WF   WSEOB SV UE OEZ B U WBE BDBX Z CB Z CWZ SWBOY BCF ZOW W CY Z WYMBZ ZOB BEB WS Z QX B YWWZB X BB CFOC ZUW B S  BUCWSE EZ MZOSOECO ZY ZY SZB  B SBT T SB  XEGBMCBE B BEB BE B EBEB  ZE BEH  B B W EC USB E B 'B\"}\n"
     ]
    }
   ],
   "source": [
    "# KeyDataset is a util that will just output the item we're interested in.\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "pipe = pipeline(model=\"hf-internal-testing/tiny-random-wav2vec2\")\n",
    "dataset = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation[:10]\")\n",
    "\n",
    "for out in pipe(KeyDataset(dataset, \"audio\")):\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94306767-c415-40dd-b963-3e1030da03fa",
   "metadata": {},
   "source": [
    "### Vision Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "962baccd-42a8-4003-9e79-b33598cf3caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.4335, 'label': 'lynx, catamount'},\n",
       " {'score': 0.0348,\n",
       "  'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'},\n",
       " {'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'},\n",
       " {'score': 0.0239, 'label': 'Egyptian cat'},\n",
       " {'score': 0.0229, 'label': 'tiger cat'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "vision_classifier = pipeline(model=\"google/vit-base-patch16-224\")\n",
    "preds = vision_classifier(\n",
    "    images=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8c6b1d5-fef1-4315-b288-112d2557ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install accelerate\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(model=\"facebook/opt-1.3b\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "output = pipe(\"This is a cool example!\", do_sample=True, top_p=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3921a3f5-d731-4b93-9f47-db01b376a050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'This is a cool example! How is it though?\\nThere is a noticeable difference between the'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bffd9597-ae05-4838-a7b8-96805247bb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "IMPORTANT: You are using gradio version 3.48.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import gradio as gr\n",
    "\n",
    "pipe = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n",
    "\n",
    "gr.Interface.from_pipeline(pipe).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9024ba65-d1bb-48ce-aa93-51cfb154393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "986cd593-6ae6-469e-87ba-5ea3ea7762b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1999, 1037, 4920, 1999, 1996, 2598, 2045, 2973, 1037, 7570, 10322, 4183, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "sequence = \"In a hole in the ground there lived a hobbit.\"\n",
    "print(tokenizer(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3abbb1bc-de6a-4702-8466-e27778ec7f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f2b1fbd-dad9-45fa-90ee-d242aaea4ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SwinBackbone were not initialized from the model checkpoint at microsoft/swin-tiny-patch4-window7-224 and are newly initialized: ['swin.hidden_states_norms.stage1.bias', 'swin.hidden_states_norms.stage1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoBackbone\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
    "model = AutoBackbone.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\", out_indices=(1,))\n",
    "\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "feature_maps = outputs.feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41bd6b86-9224-45a0-9bfa-c903d2a0d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\n",
    ")\n",
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1e9c46f-32aa-4bc9-bb40-c4ad7d65b04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d39b7c78-a1f6-4093-ad90-be11a5136248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2079, 2025, 19960, 10362, 1999, 1996, 3821, 1997, 16657, 1010, 2005, 2027, 2024, 11259, 1998, 4248, 2000, 4963, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'input_ids': tensor([[  101,  2021,  2054,  2055,  2117,  6350,  1029,   102,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2123,  1005,  1056,  2228,  2002,  4282,  2055,  2117,  6350,\n",
      "          1010, 28315,  1012,   102],\n",
      "        [  101,  2054,  2055,  5408, 14625,  1029,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(\"Do not meddle in the affairs of wizards, for they are subtle and quick to anger.\")\n",
    "print(encoded_input)\n",
    "tokenizer.decode(encoded_input[\"input_ids\"])\n",
    "batch_sentences = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925604c5-433b-4e46-bc21-eeef063ad70d",
   "metadata": {},
   "source": [
    "### Fine Tuning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d74b171e-71a7-42da-bbc0-a9a7bfa91499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16683075-cc3c-40de-b619-ee07cd1c1ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be225a384a0b4f6b9451257784906f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/650000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0828a4924e4aefa563f57eaa98df1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3df42a74-0cda-4602-aef9-dd7a5eb4ccb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "612a2f4a-bdf1-47fc-a399-ed68056c49a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab4e50c0-d978-4952-aa75-f3bdb19a3170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afe44fc6-ecb3-47f1-8d0b-e480d645bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b33f72db-708c-4a87-8175-3fc2df9ef9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")  #, eval_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63a57f09-8a59-4c8c-8576-32be8917b9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34c49cc4-50b9-45e6-9b9a-d177b0c40b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "909ea2ce-8551-4811-9666-ebed102c07ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 1:15:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=0.9601611328125, metrics={'train_runtime': 4523.3607, 'train_samples_per_second': 0.663, 'train_steps_per_second': 0.083, 'total_flos': 789354427392000.0, 'train_loss': 0.9601611328125, 'epoch': 3.0})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56c0a6c-7d6e-4ebc-9a3f-cbcc4e9bff4a",
   "metadata": {},
   "source": [
    "### Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02b20041-7e9a-4c37-8747-fbc5f7b8f77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17de0c1b93494a8285f13d8b74e4f203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df7ee311-8d4d-411d-b2b2-86a53a086c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66f56505-764a-445b-841c-d5fbac8cbdc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn\\'t match the background, and painfully one-dimensional characters cannot be overcome with a \\'sci-fi\\' setting. (I\\'m sure there are those of you out there who think Babylon 5 is good sci-fi TV. It\\'s not. It\\'s clichÃ©d and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It\\'s really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it\\'s rubbish as they have to always say \"Gene Roddenberry\\'s Earth...\" otherwise people would not continue watching. Roddenberry\\'s ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15310a14-632f-4f71-aded-c2d5dcd242f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "649f9015-761b-412f-a888-9083cec4a5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62a2f291-1b6c-47b7-a6a8-26647c56c483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7d8b2f9c6744d3ba06763ea623beee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a8e12b91fe44baad694b2a9352da55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2ba0eb4206469b8a88dc3a4def9840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_imdb = imdb.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2ec1a5c-46c7-4eb9-9205-986dfd8e1943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "31c8739e-cc49-4892-95a8-cd447a67b2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "568c548e-6c3c-4cda-8e06-b5b24dd7f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc3a7331-dd6a-4302-af9c-e3b3dcd7a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f91472f-e055-4977-b66e-02f74f85c02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90fa0c00-f1ad-4a00-a56c-88c9ec952e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/gedman4b/my_awesome_model into local empty directory.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='348' max='3126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 348/3126 1:04:44 < 8:39:50, 0.09 it/s, Epoch 0.22/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 24\u001b[0m\n\u001b[0;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_awesome_model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m    \u001b[38;5;66;03m# eval_strategy=\"epoch\",\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     push_to_hub\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     15\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     16\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[0;32m     22\u001b[0m )\n\u001b[1;32m---> 24\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1536\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1538\u001b[0m )\n\u001b[1;32m-> 1539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:1809\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1806\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   1808\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1809\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1812\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1813\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1814\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1815\u001b[0m ):\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1817\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2654\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2651\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2653\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2654\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2657\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2678\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2679\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2680\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2681\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:788\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    786\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m--> 788\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    797\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[0;32m    798\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:608\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    604\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    606\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids, inputs_embeds)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:375\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    368\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    369\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    370\u001b[0m         hidden_state,\n\u001b[0;32m    371\u001b[0m         attn_mask,\n\u001b[0;32m    372\u001b[0m         head_mask[i],\n\u001b[0;32m    373\u001b[0m     )\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 375\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:295\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;124;03m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;66;03m# Self-Attention\u001b[39;00m\n\u001b[1;32m--> 295\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[0;32m    304\u001b[0m     sa_output, sa_weights \u001b[38;5;241m=\u001b[39m sa_output  \u001b[38;5;66;03m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:226\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[1;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    221\u001b[0m mask \u001b[38;5;241m=\u001b[39m (mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mview(mask_reshp)\u001b[38;5;241m.\u001b[39mexpand_as(scores)  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[0;32m    222\u001b[0m scores \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mmasked_fill(\n\u001b[0;32m    223\u001b[0m     mask, torch\u001b[38;5;241m.\u001b[39mtensor(torch\u001b[38;5;241m.\u001b[39mfinfo(scores\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mmin)\n\u001b[0;32m    224\u001b[0m )  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[0;32m    227\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(weights)  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# Mask heads if we want to\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:1885\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1883\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1885\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1887\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_model\",\n",
    "   # eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "   # load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_imdb[\"train\"],\n",
    "    eval_dataset=tokenized_imdb[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b44623f-1cad-446d-bfd2-62cf97bc95e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e035a787fe82484c8dc5897036cba775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4dd5d8b4a284c4f88c5b0e7b7d32897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a1e305e7be4f028974304df3bb07bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa7fb20b7f64ebc95db60a35461fed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf59d8800725469087078968be11717a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b058557ff71401094879978c80857ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9ce7f6cbf64f3bba75e9c1f7eec0e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1155815cb4b6425cacecd2d68681e4fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca0ec40e-2883-4a69-9c04-f8d148a14654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f2059fb2bc44e58f1d17aadc0ace75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the cpu and disk.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Hey how are you doing today? I am really glad that you came by to read this post'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\", model=model_id, model_kwargs={\"torch_dtype\": torch.bfloat16}, device_map=\"auto\"\n",
    ")\n",
    "\n",
    "pipeline(\"Hey how are you doing today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5929e3c8-0f19-456a-8d46-31a2640a7c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd66459-db0b-452e-9699-bb405a6f265d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663228c6-c355-49c9-9678-ea8d85331d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be45185c-1bcb-4a67-a62f-706662610e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3.1-8B\"\n",
    "API_TOKEN = \"\"\n",
    "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": \"\"\"The following is a situation which requires careful thinking and analysis. Assume there are only two genders male and female and that a mother is a female and a father is a male:\n",
    "A man and his mother are in a car accident. The man's mother sadly dies. The man is rushed to the ER. When the doctor sees him, the doctor says, \"I can't operate on this man. This man is my son!\"\n",
    "How is this possible?\"\"\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "95188363-0096-4037-81fc-2721081c993f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'The model meta-llama/Meta-Llama-3.1-8B is too large to be loaded automatically (16GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14603d7f-c6da-476f-a092-84ced25f1540",
   "metadata": {},
   "source": [
    "### Meta Model Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7c8bbc3c-f294-4aa4-85b2-eece6d6d592b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e613dae7e154283b3fe4350fd9aa8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a79e972ea746469fee64a6a6d3564f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1363064609e4db1a1340ac9e901e722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model = \"meta-llama/Meta-Llama-3.1-8B-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "58bdfc3d-f38d-4c96-9467-86e79ed6db57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737ac187ee444dcb83e32aa84b87f11e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887493b1e8334321a1f5cc647461cc04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b068759d134e1daa5869dc790dc76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3723224d081a43248ee95de3e255e07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7be9fdd015c487fb4b2f7d9b272a067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de47828112ed40488224dcd4dbbb886f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829dd8298e294b4bb2ab62b62e570fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f122662992634e49837c732037479064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5aa4be28-86bc-4ff4-8506-6ba9b2daff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "sequences = pipeline(\n",
    "    'I have tomatoes, basil and cheese at home. What can I cook for dinner?\\n',\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    truncation = True,\n",
    "    max_length=400,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0e21a157-15ba-4123-bc4b-ab1325286595",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "22106431-8bf7-4321-a3ad-82fdce35d1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"I have tomatoes, basil and cheese at home. What can I cook for dinner?\\nYou have the ingredients for a classic Italian dish: Bruschetta. Here's a simple recipe:\\nIngredients:\\n- 4-6 tomatoes, diced\\n- 1/4 cup fresh basil leaves, chopped\\n- 1/2 cup grated cheese (such as mozzarella or parmesan)\\n- 4-6 slices of bread (preferably Italian bread or baguette)\\n- 2 tablespoons olive oil\\n- Salt and pepper to taste\\n\\nInstructions:\\n1. Preheat your oven to 400Â°F (200Â°C).\\n2. Slice the bread into 1/2-inch thick slices and place on a baking sheet.\\n3. Drizzle the olive oil over the bread and sprinkle with salt.\\n4. Bake the bread in the oven for 10-12 minutes, or until it's lightly toasted and crispy.\\n5. While the bread is baking, mix the diced tomatoes and chopped basil in a bowl.\\n6. Once the bread is ready, remove it from the oven and let it cool for a minute or two.\\n7. Top each slice of bread with a spoonful of the tomato-basil mixture and a sprinkle of grated cheese.\\n8. Serve immediately and enjoy!\\n\\nYou can also consider other options, such as:\\n- Grilled cheese sandwiches with tomato and basil\\n- Tomato and basil salad with a simple vinaigrette dressing\\n- Cheese and tomato omelette\\n\\nI hope this helps! Let me know if you have any other questions. (2023-02-03) (2023-02-03) (2023-02-03) (2023-02-03) (2023-02-03) (2023-02-03) (2023-02-03) (2023-02-03) (2023-02-03) (2023-02-03) (2023-\"}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5692aad2-2a22-4beb-9860-aa2e6fe4bc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
